{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generative Models for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book1 = io.open('book1.txt', 'r', encoding=\"utf8\").read().lower()\n",
    "book2 = io.open('book2.txt', 'r', encoding=\"utf8\").read().lower()\n",
    "book3 = io.open('book3.txt', 'r', encoding=\"utf8\").read().lower()\n",
    "book4 = io.open('book4.txt', 'r', encoding=\"utf8\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length 1593556\n"
     ]
    }
   ],
   "source": [
    "text = book1 + '\\n' + book2 + '\\n' + book3 + '\\n' + book4\n",
    "print('Text Length', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Characters to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Characters 99\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('Total Unique Characters', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up into subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Sequences 1593457\n"
     ]
    }
   ],
   "source": [
    "maxlen = 99\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i:i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('No. of Sequences', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    #Helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    #Function invoked at the end of each epoch. Prints generated Text.\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        generated = ''\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        generated += sentence\n",
    "        \n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            \n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            \n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = 'weights.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                            verbose=0, save_best_only=True, \n",
    "                            mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity=0.5):\n",
    "    #Get random starting Text\n",
    "    generated = ''\n",
    "    sentence = 'There are those who take mental phenomena naively, just as they would physical phenomena. This scho'.lower()\n",
    "    generated += sentence\n",
    "    \n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                             patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [print_callback, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1593457/1593457 [==============================] - 1755s 1ms/step - loss: 1.6295\n",
      "Epoch 2/30\n",
      "1593457/1593457 [==============================] - 1839s 1ms/step - loss: 1.2732\n",
      "Epoch 3/30\n",
      "1593457/1593457 [==============================] - 1800s 1ms/step - loss: 1.2229\n",
      "Epoch 4/30\n",
      "1593457/1593457 [==============================] - 2041s 1ms/step - loss: 1.1977\n",
      "Epoch 5/30\n",
      "1593457/1593457 [==============================] - 1965s 1ms/step - loss: 1.1819\n",
      "Epoch 6/30\n",
      "1593457/1593457 [==============================] - 1800s 1ms/step - loss: 1.1704\n",
      "Epoch 7/30\n",
      "1593457/1593457 [==============================] - 1811s 1ms/step - loss: 1.1613\n",
      "Epoch 8/30\n",
      "1593457/1593457 [==============================] - 1802s 1ms/step - loss: 1.1542\n",
      "Epoch 9/30\n",
      "1593457/1593457 [==============================] - 1815s 1ms/step - loss: 1.1482\n",
      "Epoch 10/30\n",
      "1593457/1593457 [==============================] - 1809s 1ms/step - loss: 1.1432\n",
      "Epoch 11/30\n",
      "1593457/1593457 [==============================] - 1808s 1ms/step - loss: 1.1388\n",
      "Epoch 12/30\n",
      "1593457/1593457 [==============================] - 1803s 1ms/step - loss: 1.1345\n",
      "Epoch 13/30\n",
      "1593457/1593457 [==============================] - 1787s 1ms/step - loss: 1.1310\n",
      "Epoch 14/30\n",
      "1593457/1593457 [==============================] - 1786s 1ms/step - loss: 1.1279\n",
      "Epoch 15/30\n",
      "1593457/1593457 [==============================] - 1782s 1ms/step - loss: 1.1251\n",
      "Epoch 16/30\n",
      "1593457/1593457 [==============================] - 1787s 1ms/step - loss: 1.1226\n",
      "Epoch 17/30\n",
      "1593457/1593457 [==============================] - 1799s 1ms/step - loss: 1.1205\n",
      "Epoch 18/30\n",
      "1593457/1593457 [==============================] - 1797s 1ms/step - loss: 1.1177\n",
      "Epoch 19/30\n",
      "1593457/1593457 [==============================] - 1800s 1ms/step - loss: 1.1157\n",
      "Epoch 20/30\n",
      "1593457/1593457 [==============================] - 1792s 1ms/step - loss: 1.1140\n",
      "Epoch 21/30\n",
      "1593457/1593457 [==============================] - 1791s 1ms/step - loss: 1.1123\n",
      "Epoch 22/30\n",
      "1593457/1593457 [==============================] - 1808s 1ms/step - loss: 1.1100\n",
      "Epoch 23/30\n",
      "1593457/1593457 [==============================] - 1812s 1ms/step - loss: 1.1087\n",
      "Epoch 24/30\n",
      "1593457/1593457 [==============================] - 1807s 1ms/step - loss: 1.1072\n",
      "Epoch 25/30\n",
      "1593457/1593457 [==============================] - 1796s 1ms/step - loss: 1.1059\n",
      "Epoch 26/30\n",
      "1593457/1593457 [==============================] - 1793s 1ms/step - loss: 1.1043\n",
      "Epoch 27/30\n",
      "1593457/1593457 [==============================] - 1798s 1ms/step - loss: 1.1028\n",
      "Epoch 28/30\n",
      "1593457/1593457 [==============================] - 1798s 1ms/step - loss: 1.1019\n",
      "Epoch 29/30\n",
      "1593457/1593457 [==============================] - 1800s 1ms/step - loss: 1.1006\n",
      "Epoch 30/30\n",
      "1593457/1593457 [==============================] - 1793s 1ms/step - loss: 1.0993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f593a36ee90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=1024, epochs=30, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('TextGenerator.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively, just as they would physical phenomena. this school event of entities of physics when it is only to be just as we can be completed in the end of a property of the problems of the things to be accounted by external wholly important belong to the self-evidence of the sense of sense-data of the proposition of the attempt to the distinction of the sense which we may have been defined by the advances of sense-data of the subject of which the objective which we have allowed to be the same and proposition of the two of the whole, while we have no different perspectives that he is the sense of the senses of what is inferred from the matter of a sensible to the whole of the way and a sensation of the cause of the\n",
      "sense who have a result of an extent of the law of things which is a relation of many with what is the previous sense-data when it is the physical objects and particular who were to the sense of the sense of the whole of the sense of the state of a collection of the metaphysical object and who comes heart of sense-data, on the object\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End of Question - 1. Next Question attached in* **Sub7-Notebook_K=4.ipynb**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
