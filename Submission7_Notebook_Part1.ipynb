{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generative Models for Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "book1 = io.open('book1.txt', 'r', encoding=\"utf8\").read().lower()\n",
    "book2 = io.open('book2.txt', 'r', encoding=\"utf8\").read().lower()\n",
    "book3 = io.open('book3.txt', 'r', encoding=\"utf8\").read().lower()\n",
    "book4 = io.open('book4.txt', 'r', encoding=\"utf8\").read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Length 1593556\n"
     ]
    }
   ],
   "source": [
    "text = book1 + '\\n' + book2 + '\\n' + book3 + '\\n' + book4\n",
    "print('Text Length', len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Characters to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Characters 99\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('Total Unique Characters', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up into subsequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Sequences 1593457\n"
     ]
    }
   ],
   "source": [
    "maxlen = 99\n",
    "step = 1\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i:i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('No. of Sequences', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature):\n",
    "    #Helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    #Function invoked at the end of each epoch. Prints generated Text.\n",
    "    #print('\\n----- Generating Text after Epoch: %d'%epoch)\n",
    "    \n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    \n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        #print('----- Diversity:', diversity)\n",
    "        \n",
    "        generated = ''\n",
    "        sentence = text[start_index : start_index + maxlen]\n",
    "        generated += sentence\n",
    "        #print('----- Generating with seed:\"'+sentence+'\"')\n",
    "        #sys.stdout.write(generated)\n",
    "        \n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1\n",
    "            \n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "            \n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "            \n",
    "            #sys.stdout.write(next_char)\n",
    "            #sys.stdout.flush()\n",
    "        #print('\\n')\n",
    "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "filepath = 'weights.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
    "                            verbose=1, save_best_only=True, \n",
    "                            mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length, diversity):\n",
    "    #Get random starting Text\n",
    "    #start_index = random.randint(0, len(text)-maxlen-1)\n",
    "    generated = ''\n",
    "    sentence = 'There are those who take mental phenomena naively, just as they would physical phenomena. This scho'.lower()\n",
    "    #sentence = text[start_index: start_index + maxlen]\n",
    "    generated += sentence\n",
    "    \n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "        \n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,\n",
    "                             patience=1, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [print_callback, checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1593457/1593457 [==============================] - 6563s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00001: loss did not improve from inf\n",
      "Epoch 2/30\n",
      "1593457/1593457 [==============================] - 6418s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00002: loss did not improve from inf\n",
      "Epoch 3/30\n",
      "1593457/1593457 [==============================] - 6368s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00003: loss did not improve from inf\n",
      "Epoch 4/30\n",
      "1593457/1593457 [==============================] - 6509s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00004: loss did not improve from inf\n",
      "Epoch 5/30\n",
      "1593457/1593457 [==============================] - 6458s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00005: loss did not improve from inf\n",
      "Epoch 6/30\n",
      "1593457/1593457 [==============================] - 6240s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00006: loss did not improve from inf\n",
      "Epoch 7/30\n",
      "1593457/1593457 [==============================] - 6265s 4ms/step - loss: nan\n",
      "\n",
      "Epoch 00007: loss did not improve from inf\n",
      "Epoch 8/30\n",
      " 260920/1593457 [===>..........................] - ETA: 1:27:35 - loss: nan"
     ]
    }
   ],
   "source": [
    "model.fit(x, y, batch_size=20, epochs=30, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate_text(1000, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
